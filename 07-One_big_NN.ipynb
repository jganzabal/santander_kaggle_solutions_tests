{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from CyclicLR import CyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    f1 = lambda: tf.constant(0, dtype=tf.float64)\n",
    "    f2 = lambda: tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "    \n",
    "    r = tf.case([(tf.equal(tf.reduce_sum(y_true), tf.constant(0, dtype=tf.float32)), f1),\n",
    "                 (tf.equal(tf.reduce_sum(tf.subtract(tf.ones_like(y_true), y_true)), tf.constant(0, dtype=tf.float32)), f1)\n",
    "                ], default=f2)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_with_counts.csv')\n",
    "y = df_train['target'].values\n",
    "df_train_X = df_train.drop(columns=['ID_code', 'target'])\n",
    "df_train_X_normalized = (df_train_X - df_train_X.mean(axis=0))/df_train_X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_vars = 200\n",
    "\n",
    "def get_data(trn_idx, val_idx, N_vars = 200):\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    for i in range(N_vars):\n",
    "        X_train.append(df_train_X_normalized[[f'var_{i}', f'var_{i}_FE']].values[trn_idx])\n",
    "        X_val.append(df_train_X_normalized[[f'var_{i}', f'var_{i}_FE']].values[val_idx])\n",
    "    return X_train, X_val\n",
    "# trn_idx = np.arange(160_000)\n",
    "# val_idx = np.arange(160_000, 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(N_vars=200):\n",
    "    denseOuts = []\n",
    "    inputs = []\n",
    "    for i in range(N_vars):\n",
    "        inp = Input((2,))\n",
    "        inputs.append(inp)\n",
    "        dense_out = Dense(1000)(inp)\n",
    "        # dense_1000_out = Activation('relu')(dense_out)\n",
    "        # dense_1000_out = LeakyReLU()(dense_out)\n",
    "        denseOuts.append(dense_out)\n",
    "    x = Concatenate()(denseOuts)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(N_vars=200):\n",
    "    denseOuts = []\n",
    "    inputs = []\n",
    "    for i in range(N_vars):\n",
    "        inp = Input((2,))\n",
    "        inputs.append(inp)\n",
    "        dense_out = Dense(1000)(inp)\n",
    "        # dense_1000_out = Activation('relu')(dense_out)\n",
    "        dense_out = LeakyReLU()(dense_out)\n",
    "        dense_out = Dense(1)(dense_out)\n",
    "        dense_out = LeakyReLU()(dense_out)\n",
    "        denseOuts.append(dense_out)\n",
    "    x = Concatenate()(denseOuts)\n",
    "    # x = BatchNormalization()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file_name = 'best_full_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_407 (InputLayer)          (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_408 (InputLayer)          (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_414 (Dense)               (None, 1000)         3000        input_407[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_416 (Dense)               (None, 1000)         3000        input_408[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1000)         0           dense_414[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 1000)         0           dense_416[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_415 (Dense)               (None, 1)            1001        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_417 (Dense)               (None, 1)            1001        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 1)            0           dense_415[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1)            0           dense_417[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2)            0           leaky_re_lu_9[0][0]              \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_418 (Dense)               (None, 1)            3           concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,005\n",
      "Trainable params: 8,005\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(N_vars=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 00050: val_auc improved from 0.91503 to 0.91511, saving model to best_full_model.h5\n",
    "# Epoch 00017: val_auc did not improve from 0.91834\n",
    "# Epoch 00012: val_auc improved from 0.91837 to 0.91853, saving model to best_full_model.h5\n",
    "# Epoch 00029: val_auc did not improve from 0.91857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "##################Fold 0#######################\n",
      "###############################################\n",
      "Got train and val data!\n",
      "Train on 159999 samples, validate on 40001 samples\n",
      "Epoch 1/70\n",
      "  1536/159999 [..............................] - ETA: 21:48 - loss: 0.7000 - auc: 0.5097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.384074). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159999/159999 [==============================] - 58s 360us/step - loss: 0.2819 - auc: 0.7770 - val_loss: 0.2269 - val_auc: 0.8669\n",
      "Epoch 2/70\n",
      "159999/159999 [==============================] - 44s 273us/step - loss: 0.2238 - auc: 0.8744 - val_loss: 0.2200 - val_auc: 0.8790\n",
      "Epoch 3/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2166 - auc: 0.8838 - val_loss: 0.2151 - val_auc: 0.8840\n",
      "Epoch 4/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2143 - auc: 0.8861 - val_loss: 0.2118 - val_auc: 0.8889\n",
      "Epoch 5/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2103 - auc: 0.8910 - val_loss: 0.2091 - val_auc: 0.8914\n",
      "Epoch 6/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2051 - auc: 0.8965 - val_loss: 0.2021 - val_auc: 0.8979\n",
      "Epoch 7/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1999 - auc: 0.9021 - val_loss: 0.1991 - val_auc: 0.9017\n",
      "Epoch 8/70\n",
      "159999/159999 [==============================] - 44s 275us/step - loss: 0.1948 - auc: 0.9073 - val_loss: 0.1966 - val_auc: 0.9041\n",
      "Epoch 9/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1938 - auc: 0.9086 - val_loss: 0.1996 - val_auc: 0.9015\n",
      "Epoch 10/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1983 - auc: 0.9044 - val_loss: 0.2008 - val_auc: 0.8997\n",
      "Epoch 11/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2022 - auc: 0.9016 - val_loss: 0.2071 - val_auc: 0.8958\n",
      "Epoch 12/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2042 - auc: 0.8986 - val_loss: 0.2052 - val_auc: 0.8937\n",
      "Epoch 13/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.2044 - auc: 0.8993 - val_loss: 0.2140 - val_auc: 0.9004\n",
      "Epoch 14/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1991 - auc: 0.9038 - val_loss: 0.2007 - val_auc: 0.9007\n",
      "Epoch 15/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1949 - auc: 0.9072 - val_loss: 0.1975 - val_auc: 0.9047\n",
      "Epoch 16/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1907 - auc: 0.9115 - val_loss: 0.1941 - val_auc: 0.9068\n",
      "Epoch 17/70\n",
      "159999/159999 [==============================] - 44s 274us/step - loss: 0.1900 - auc: 0.9125 - val_loss: 0.1957 - val_auc: 0.9053\n",
      "Epoch 18/70\n",
      "142848/159999 [=========================>....] - ETA: 4s - loss: 0.1942 - auc: 0.9087"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2f4fe5b02646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#                            mc],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#                            #clr],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m               validation_data=(X_val, y[val_idx]))\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finish training with lr {lr}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "epochs = 70\n",
    "patience = 15\n",
    "bs = 512\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df_train_X_normalized, y)):\n",
    "    print('###############################################')\n",
    "    print(f'##################Fold {fold}#######################')\n",
    "    print('###############################################')\n",
    "    X_train, X_val = get_data(trn_idx, val_idx)\n",
    "    print('Got train and val data!')\n",
    "    lrs = [0.001, 0.0001, 0.00005]\n",
    "    model = get_model()\n",
    "    for lr in lrs:\n",
    "        model.compile(Adam(lr=lr, decay=0), loss='binary_crossentropy', metrics=[auc])\n",
    "        es = EarlyStopping(monitor='val_auc', patience=patience, mode='max', verbose=1)\n",
    "        mc = ModelCheckpoint(best_model_file_name, monitor='val_auc', mode='max', verbose=1, save_best_only=True)\n",
    "        tr_iter_in_epoch = 160_000//bs\n",
    "        clr = CyclicLR(base_lr=0.0001, max_lr=0.005, step_size=4*tr_iter_in_epoch, mode='exp_range', gamma=0.99994)\n",
    "        # First train\n",
    "        model.fit(X_train, y[trn_idx], \n",
    "              epochs=epochs, batch_size=bs, \n",
    "              verbose=1,\n",
    "              callbacks = [clr],\n",
    "#               callbacks = [es, \n",
    "#                            mc], \n",
    "#                            #clr],\n",
    "              validation_data=(X_val, y[val_idx]))\n",
    "        print(f'Finish training with lr {lr}')\n",
    "        model = get_model()\n",
    "        # Load weights from ModelCheckpoint\n",
    "        model.load_weights(best_model_file_name)\n",
    "        # Save them to disk\n",
    "        model.save_weights(f'big_NN_2_fold_{fold}_lr_{lr}.hdf5')\n",
    "        print('weights saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa0ab34df28>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"CLR - Custom Iteration-Policy\")\n",
    "plt.plot(clr.history['iterations'], clr.history['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "tr_it_per_epoch = 160_000//(bs)\n",
    "print(tr_it_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "##################Fold 0#######################\n",
    "###############################################\n",
    "Got train and val data!\n",
    "\n",
    "Epoch 00001: val_auc improved from -inf to 0.88278, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00002: val_auc improved from 0.88278 to 0.89449, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00003: val_auc improved from 0.89449 to 0.89904, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00004: val_auc improved from 0.89904 to 0.90180, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00005: val_auc improved from 0.90180 to 0.90400, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00006: val_auc improved from 0.90400 to 0.90428, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00007: val_auc improved from 0.90428 to 0.90601, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00008: val_auc did not improve from 0.90601\n",
    "\n",
    "Epoch 00009: val_auc improved from 0.90601 to 0.90606, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00010: val_auc improved from 0.90606 to 0.90734, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00011: val_auc did not improve from 0.90734\n",
    "\n",
    "Epoch 00012: val_auc improved from 0.90734 to 0.90926, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00013: val_auc did not improve from 0.90926\n",
    "\n",
    "Epoch 00014: val_auc did not improve from 0.90926\n",
    "\n",
    "Epoch 00015: val_auc did not improve from 0.90926\n",
    "\n",
    "Epoch 00016: val_auc improved from 0.90926 to 0.90963, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00017: val_auc improved from 0.90963 to 0.90992, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00018: val_auc did not improve from 0.90992\n",
    "\n",
    "Epoch 00019: val_auc improved from 0.90992 to 0.91158, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00020: val_auc did not improve from 0.91158\n",
    "\n",
    "Epoch 00021: val_auc improved from 0.91158 to 0.91254, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00022: val_auc did not improve from 0.91254\n",
    "\n",
    "Epoch 00023: val_auc improved from 0.91254 to 0.91382, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00024: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00025: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00026: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00027: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00028: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00029: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00030: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00031: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00032: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00033: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00034: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00035: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00036: val_auc did not improve from 0.91382\n",
    "\n",
    "Epoch 00037: val_auc improved from 0.91382 to 0.91443, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00038: val_auc did not improve from 0.91443\n",
    "\n",
    "Epoch 00044: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00045: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00046: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00047: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00048: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00049: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00050: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00051: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00052: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00053: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00054: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00055: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00056: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00057: val_auc did not improve from 0.91549\n",
    "\n",
    "Epoch 00058: val_auc improved from 0.91549 to 0.91555, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00059: val_auc did not improve from 0.91555\n",
    "\n",
    "Epoch 00060: val_auc improved from 0.91555 to 0.91606, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00061: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00062: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00063: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00064: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00065: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00066: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00067: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00068: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00069: val_auc did not improve from 0.91606\n",
    "\n",
    "Epoch 00070: val_auc improved from 0.91606 to 0.91670, saving model to best_full_model.h5\n",
    "Finish training with lr 0.001\n",
    "weights saved\n",
    "\n",
    "Epoch 00001: val_auc improved from -inf to 0.91868, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00002: val_auc improved from 0.91868 to 0.91898, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00003: val_auc did not improve from 0.91898\n",
    "\n",
    "Epoch 00004: val_auc did not improve from 0.91898\n",
    "\n",
    "Epoch 00005: val_auc improved from 0.91898 to 0.91899, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00006: val_auc did not improve from 0.91899\n",
    "\n",
    "Epoch 00007: val_auc did not improve from 0.91899\n",
    "\n",
    "Epoch 00008: val_auc did not improve from 0.91899\n",
    "\n",
    "Epoch 00009: val_auc improved from 0.91899 to 0.91905, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00010: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00011: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00012: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00013: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00014: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00015: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00016: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00017: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00018: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00019: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00020: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00021: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00022: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00023: val_auc did not improve from 0.91905\n",
    "\n",
    "Epoch 00024: val_auc did not improve from 0.91905\n",
    "Epoch 00024: early stopping\n",
    "Finish training with lr 0.0001\n",
    "weights saved\n",
    "\n",
    "Epoch 00001: val_auc improved from -inf to 0.91900, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00002: val_auc improved from 0.91900 to 0.91900, saving model to best_full_model.h5\n",
    "\n",
    "Epoch 00003: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00004: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00005: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00006: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00007: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00008: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00009: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00010: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00011: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00012: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00013: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00014: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00015: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00016: val_auc did not improve from 0.91900\n",
    "\n",
    "Epoch 00017: val_auc did not improve from 0.91900\n",
    "Epoch 00017: early stopping\n",
    "Finish training with lr 5e-05\n",
    "weights saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
