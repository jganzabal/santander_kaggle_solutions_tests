{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Concatenate, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    f1 = lambda: tf.constant(0, dtype=tf.float64)\n",
    "    f2 = lambda: tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "    \n",
    "    r = tf.case([(tf.equal(tf.reduce_sum(y_true), tf.constant(0, dtype=tf.float32)), f1),\n",
    "                 (tf.equal(tf.reduce_sum(tf.subtract(tf.ones_like(y_true), y_true)), tf.constant(0, dtype=tf.float32)), f1)\n",
    "                ], default=f2)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_with_counts.csv')\n",
    "y = df_train['target'].values\n",
    "df_train_X = df_train.drop(columns=['ID_code', 'target'])\n",
    "df_train_X_normalized = (df_train_X - df_train_X.mean(axis=0))/df_train_X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_FE</th>\n",
       "      <th>var_191_FE</th>\n",
       "      <th>var_192_FE</th>\n",
       "      <th>var_193_FE</th>\n",
       "      <th>var_194_FE</th>\n",
       "      <th>var_195_FE</th>\n",
       "      <th>var_196_FE</th>\n",
       "      <th>var_197_FE</th>\n",
       "      <th>var_198_FE</th>\n",
       "      <th>var_199_FE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577100</td>\n",
       "      <td>-1.273734</td>\n",
       "      <td>0.460090</td>\n",
       "      <td>1.750966</td>\n",
       "      <td>-0.020872</td>\n",
       "      <td>0.491725</td>\n",
       "      <td>-0.692319</td>\n",
       "      <td>1.624021</td>\n",
       "      <td>2.104313</td>\n",
       "      <td>0.488123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>2.010107</td>\n",
       "      <td>0.654904</td>\n",
       "      <td>0.514849</td>\n",
       "      <td>2.809453</td>\n",
       "      <td>-0.579089</td>\n",
       "      <td>1.740723</td>\n",
       "      <td>0.871209</td>\n",
       "      <td>0.520762</td>\n",
       "      <td>0.042849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269958</td>\n",
       "      <td>-0.622136</td>\n",
       "      <td>-0.144986</td>\n",
       "      <td>-0.772678</td>\n",
       "      <td>-1.011350</td>\n",
       "      <td>1.527378</td>\n",
       "      <td>0.761581</td>\n",
       "      <td>1.865887</td>\n",
       "      <td>-1.895580</td>\n",
       "      <td>-0.673628</td>\n",
       "      <td>...</td>\n",
       "      <td>3.051745</td>\n",
       "      <td>0.542409</td>\n",
       "      <td>0.654904</td>\n",
       "      <td>-0.679281</td>\n",
       "      <td>0.162290</td>\n",
       "      <td>-0.883793</td>\n",
       "      <td>1.017512</td>\n",
       "      <td>2.429459</td>\n",
       "      <td>1.001115</td>\n",
       "      <td>0.042849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.681112</td>\n",
       "      <td>-0.276066</td>\n",
       "      <td>-0.130752</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>-0.157928</td>\n",
       "      <td>-0.858653</td>\n",
       "      <td>-0.989044</td>\n",
       "      <td>1.785603</td>\n",
       "      <td>-0.286601</td>\n",
       "      <td>-1.714792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615468</td>\n",
       "      <td>0.542409</td>\n",
       "      <td>-0.241114</td>\n",
       "      <td>-0.679281</td>\n",
       "      <td>-0.896576</td>\n",
       "      <td>-1.493201</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.425994</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>0.042849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125158</td>\n",
       "      <td>-0.129425</td>\n",
       "      <td>0.347543</td>\n",
       "      <td>-1.444036</td>\n",
       "      <td>1.841835</td>\n",
       "      <td>-0.426742</td>\n",
       "      <td>-1.173890</td>\n",
       "      <td>-1.106680</td>\n",
       "      <td>0.045292</td>\n",
       "      <td>0.935693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602671</td>\n",
       "      <td>-0.436055</td>\n",
       "      <td>-0.241114</td>\n",
       "      <td>0.514849</td>\n",
       "      <td>0.162290</td>\n",
       "      <td>0.335022</td>\n",
       "      <td>1.740723</td>\n",
       "      <td>-1.354863</td>\n",
       "      <td>-0.920295</td>\n",
       "      <td>0.042849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.277303</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>-1.788859</td>\n",
       "      <td>-1.778093</td>\n",
       "      <td>-0.213578</td>\n",
       "      <td>-0.574155</td>\n",
       "      <td>0.678888</td>\n",
       "      <td>-2.228820</td>\n",
       "      <td>1.108634</td>\n",
       "      <td>0.108366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>2.010107</td>\n",
       "      <td>-1.734476</td>\n",
       "      <td>-1.276346</td>\n",
       "      <td>-1.426008</td>\n",
       "      <td>0.639725</td>\n",
       "      <td>1.740723</td>\n",
       "      <td>-0.241827</td>\n",
       "      <td>-0.920295</td>\n",
       "      <td>0.042849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1    var_10   var_100   var_101   var_102   var_103  \\\n",
       "0 -0.577100 -1.273734  0.460090  1.750966 -0.020872  0.491725 -0.692319   \n",
       "1  0.269958 -0.622136 -0.144986 -0.772678 -1.011350  1.527378  0.761581   \n",
       "2 -0.681112 -0.276066 -0.130752  0.675978 -0.157928 -0.858653 -0.989044   \n",
       "3  0.125158 -0.129425  0.347543 -1.444036  1.841835 -0.426742 -1.173890   \n",
       "4 -0.277303  0.035610 -1.788859 -1.778093 -0.213578 -0.574155  0.678888   \n",
       "\n",
       "    var_104   var_105   var_106     ...      var_190_FE  var_191_FE  \\\n",
       "0  1.624021  2.104313  0.488123     ...        0.006398    2.010107   \n",
       "1  1.865887 -1.895580 -0.673628     ...        3.051745    0.542409   \n",
       "2  1.785603 -0.286601 -1.714792     ...        0.615468    0.542409   \n",
       "3 -1.106680  0.045292  0.935693     ...       -0.602671   -0.436055   \n",
       "4 -2.228820  1.108634  0.108366     ...        0.006398    2.010107   \n",
       "\n",
       "   var_192_FE  var_193_FE  var_194_FE  var_195_FE  var_196_FE  var_197_FE  \\\n",
       "0    0.654904    0.514849    2.809453   -0.579089    1.740723    0.871209   \n",
       "1    0.654904   -0.679281    0.162290   -0.883793    1.017512    2.429459   \n",
       "2   -0.241114   -0.679281   -0.896576   -1.493201    0.294300    0.425994   \n",
       "3   -0.241114    0.514849    0.162290    0.335022    1.740723   -1.354863   \n",
       "4   -1.734476   -1.276346   -1.426008    0.639725    1.740723   -0.241827   \n",
       "\n",
       "   var_198_FE  var_199_FE  \n",
       "0    0.520762    0.042849  \n",
       "1    1.001115    0.042849  \n",
       "2    0.040410    0.042849  \n",
       "3   -0.920295    0.042849  \n",
       "4   -0.920295    0.042849  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_X_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, df_train_X, df_train_y, batch_size=256, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.df_train_X = df_train_X\n",
    "        self.df_train_y = df_train_y\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return self.X_train[indexes], self.y_train[indexes]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        print('epoch ended')\n",
    "        self.X_train, self.y_train = shuffle_data(self.df_train_X, self.df_train_y)\n",
    "#         self.X_train = self.df_train_X.values\n",
    "#         self.y_train = self.df_train_y\n",
    "        self.indexes = np.arange(len(self.X_train))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y):\n",
    "    x1 = x[y==1]\n",
    "    X_ones = np.zeros(x1.shape)\n",
    "    ids = np.arange(x1.shape[0])\n",
    "    for c in range(200):\n",
    "        np.random.shuffle(ids)\n",
    "        X_ones[:, [c,c+200]] = x1[[f'var_{c}', f'var_{c}_FE']].values[ids]\n",
    "    \n",
    "    x0 = x[y==0].copy() \n",
    "    X_zeros = np.zeros(x0.shape)\n",
    "    ids = np.arange(x0.shape[0])\n",
    "    for c in range(200):\n",
    "        np.random.shuffle(ids)\n",
    "        X_zeros[:, [c,c+200]] = x0[[f'var_{c}', f'var_{c}_FE']].values[ids]\n",
    "\n",
    "    return np.append(X_zeros, X_ones, axis=0), np.append(np.zeros(len(X_zeros)), np.ones(len(X_ones)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_shape=(400,), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              401000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 402,001\n",
      "Trainable params: 402,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file_name = 'best_full_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "##################Fold 0#######################\n",
      "###############################################\n",
      "Got train and val data!\n",
      "epoch ended\n",
      "Epoch 1/1000\n",
      "4997/4999 [============================>.] - ETA: 0s - loss: 0.2508 - auc: 0.8119epoch ended\n",
      "4999/4999 [==============================] - 10s 2ms/step - loss: 0.2509 - auc: 0.8119 - val_loss: 0.4491 - val_auc: 0.4963\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.49633, saving model to best_full_model.h5\n",
      "Epoch 2/1000\n",
      "4984/4999 [============================>.] - ETA: 0s - loss: 0.2437 - auc: 0.8194epoch ended\n",
      "4999/4999 [==============================] - 10s 2ms/step - loss: 0.2437 - auc: 0.8191 - val_loss: 0.4501 - val_auc: 0.4972\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.49633 to 0.49722, saving model to best_full_model.h5\n",
      "Epoch 3/1000\n",
      "2975/4999 [================>.............] - ETA: 3s - loss: 0.2423 - auc: 0.8285"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6daafcfbe546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                            mc], \n\u001b[1;32m     25\u001b[0m                            \u001b[0;31m#clr],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m               validation_data=(X_val, y[val_idx]))\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finish training with lr {lr}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "patience = 1000\n",
    "epochs = 1000\n",
    "bs = 512\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df_train_X_normalized, y)):\n",
    "    print('###############################################')\n",
    "    print(f'##################Fold {fold}#######################')\n",
    "    print('###############################################')\n",
    "    X_val = df_train_X_normalized.values[val_idx]\n",
    "    \n",
    "    print('Got train and val data!')\n",
    "    lrs = [0.001, 0.0001, 0.00005]\n",
    "    model = get_model()\n",
    "    generator = DataGenerator(df_train_X_normalized.iloc[trn_idx], y[trn_idx], batch_size=bs)\n",
    "    for lr in lrs:\n",
    "        model.compile(Adam(lr=lr, decay=0), loss='binary_crossentropy', metrics=[auc])\n",
    "        es = EarlyStopping(monitor='val_auc', patience=patience, mode='max', verbose=1)\n",
    "        mc = ModelCheckpoint(best_model_file_name, monitor='val_auc', mode='max', verbose=1, save_best_only=True)\n",
    "        # First train\n",
    "        model.fit_generator(generator, \n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              callbacks = [es, \n",
    "                           mc], \n",
    "                           #clr],\n",
    "              validation_data=(X_val, y[val_idx]))\n",
    "        print(f'Finish training with lr {lr}')\n",
    "        model = get_model()\n",
    "        # Load weights from ModelCheckpoint\n",
    "        model.load_weights(best_model_file_name)\n",
    "        # Save them to disk\n",
    "        model.save_weights(f'big_NN_simple_fold_{fold}_lr_{lr}.hdf5')\n",
    "        print('weights saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
